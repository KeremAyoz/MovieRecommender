{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from auto_encoder.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "import ast\n",
    "import pandas\n",
    "from numpy import array  \n",
    "import nbimporter\n",
    "import auto_encoder as aec\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column(matrix, i):\n",
    "    return [row[i] for row in matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Linking Id's\n",
    "'''\n",
    "project_root = os.path.dirname(os.path.abspath(\"\"))\n",
    "data_path = os.path.join(project_root, \"data\\\\ratings.csv\")\n",
    "rating = pandas.read_csv(data_path)\n",
    "\n",
    "project_root = os.path.dirname(os.path.abspath(\"\"))\n",
    "data_path = os.path.join(project_root, \"data\\\\links.csv\")\n",
    "links = pandas.read_csv(data_path)\n",
    "\n",
    "project_root = os.path.dirname(os.path.abspath(\"\"))\n",
    "data_path = os.path.join(project_root, \"data\\\\movies_metadata.csv\")\n",
    "movie_meta = pandas.read_csv(data_path)\n",
    "\n",
    "joined = links.set_index('tmdbId').join(movie_meta.set_index('id'))\n",
    "\n",
    "writer = pandas.ExcelWriter('linked_movieIds.xlsx')\n",
    "joined.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing less-voted movies & least frequent voters from ratings.csv\n",
    "'''\n",
    "project_root = os.path.dirname(os.path.abspath(\"\"))\n",
    "data_path = os.path.join(project_root, \"data\\\\ratings.csv\")\n",
    "rating = pandas.read_csv(data_path, engine='python')\n",
    "\n",
    "project_root = os.path.dirname(os.path.abspath(\"\"))\n",
    "data_path = os.path.join(project_root, \"data\\\\movie_votecount.csv\")\n",
    "vote_count = pandas.read_csv(data_path)\n",
    "\n",
    "votes = column(vote_count.values, 0)\n",
    "ratings_updated = rating.loc[rating[\"movieId\"].isin(votes)]\n",
    "\n",
    "project_root = os.path.dirname(os.path.abspath(\"\"))\n",
    "data_path = os.path.join(project_root, \"data\\\\user_votecount.csv\")\n",
    "user_vote = pandas.read_csv(data_path)\n",
    "\n",
    "votes = column(user_vote.values, 0)\n",
    "ratings_updated = ratings_updated.loc[ratings[\"userId\"].isin(votes)]\n",
    "\n",
    "file = open(\"ratings_updated\", \"wb\")\n",
    "pickle.dump(ratings_updated, file)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = open(\"ratings_updated\", \"rb\")\n",
    "rating = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Removing less-voted movies & least frequent voters from ratings.csv\n",
    "'''\n",
    "project_root = os.path.dirname(os.path.abspath(\"\"))\n",
    "data_path = os.path.join(project_root, \"data\\\\movie_votecount2.csv\")\n",
    "movie_vote = pandas.read_csv(data_path)\n",
    "votes = column(movie_vote.values, 0)\n",
    "ratings_updated = rating.loc[rating[\"movieId\"].isin(votes)]\n",
    "\n",
    "project_root = os.path.dirname(os.path.abspath(\"\"))\n",
    "data_path = os.path.join(project_root, \"data\\\\user_votecount2.csv\")\n",
    "user_vote = pandas.read_csv(data_path)\n",
    "\n",
    "votes = column(user_vote.values, 0)\n",
    "ratings_updated = ratings_updated.loc[rating[\"userId\"].isin(votes)]\n",
    "file = open(\"ratings_updated_2\", \"wb\")\n",
    "pickle.dump(ratings_updated, file)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"ratings_updated_2\", \"rb\")\n",
    "ratings_updated = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movie matrix build\n",
    "movies = ratings_updated[\"movieId\"]\n",
    "movies = set(movies)\n",
    "movies = sorted(movies, key=lambda x: int(x), reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User matrix build\n",
    "users = ratings_updated[\"userId\"]\n",
    "users = set(users)\n",
    "users = sorted(users, key=lambda x: int(x), reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-movie matrix build\n",
    "user_movie = np.zeros((len(users),len(movies)), dtype=float)\n",
    "\n",
    "project_root = os.path.dirname(os.path.abspath(\"\"))\n",
    "data_path = os.path.join(project_root, \"data\\\\movies.csv\")\n",
    "movies_meta = pandas.read_csv(data_path, encoding = \"ISO-8859-1\")\n",
    "\n",
    "# Fill non-rated movies as the average rating of that movie\n",
    "for i in range(len(movies)):\n",
    "    rating_of_i = (movies_meta.loc[movies_meta[\"movieId\"] == movies[i]])[\"vote_average\"].values[0]\n",
    "    x = np.full((len(users),), rating_of_i / 2, dtype=float)\n",
    "    user_movie[:,i] = x\n",
    "\n",
    "for index, row in ratings_updated.iterrows():\n",
    "    user_movie[users.index(row['userId'])][movies.index(row['movieId'])] = row['rating']\n",
    "    \n",
    "print(np.shape(user_movie))\n",
    "file = open(\"user_movie\", \"wb\")\n",
    "pickle.dump(user_movie, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load user-movie matrix\n",
    "file = open(\"user_movie\", \"rb\")\n",
    "user_movie = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the Autoencoder to get user features\n",
    "neuron_list = [499,250,125,250,499]\n",
    "nn = aec.Autoencoder(neuron_list, 0.002, 300)\n",
    "inp = np.transpose([np.transpose(user_movie)])\n",
    "print(np.shape(inp))\n",
    "err = nn.train(inp,inp, 10)\n",
    "plt.plot(err)\n",
    "plt.show()\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract user-features after training\n",
    "features = []\n",
    "for i in range(len(user_movie)):\n",
    "    encoded = nn.encode(inp[i])\n",
    "    features.append(encoded)\n",
    "\n",
    "user_features = []\n",
    "for i in range(len(users)):\n",
    "    user_features.append([users[i], features[i]])\n",
    "file = open(\"user_features\", \"wb\")\n",
    "pickle.dump(user_features, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
